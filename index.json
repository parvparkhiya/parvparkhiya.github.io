[{"authors":null,"categories":null,"content":"I am a Robotics Engineer at ISEE working on perception and mapping aspects of the autonomous yard truck. I graduated from Carnegie Mellon University, School of Computer Science in Master of Science in Robotics System Development. My undergraduation was in Electronics and Communication Engineering (ECE), International Institute of Information Technology (IIIT), Hyderabad, India.\nI am passionate about all things storytelling in various forms from novels, video games (especially), podcasts to comics. You can play a game I worked on a while back here and checkout my personal blog here\nDownload my resumé.\n","date":1543708800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1543708800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Robotics Engineer at ISEE working on perception and mapping aspects of the autonomous yard truck. I graduated from Carnegie Mellon University, School of Computer Science in Master of Science in Robotics System Development.","tags":null,"title":"Parv Parkhiya","type":"authors"},{"authors":null,"categories":null,"content":"Autonomous vehicles operating in the real world will not always know about all obstacles in the environment. Thus, the vehicle must have the ability to plan and re-plan trajectories around known obstacles and emerging obstacles in the environment. Currently, there are many trajectory search algorithms for autonomous driving vehicles. In this paper, we explore the most prominent trajectory search algorithms like RRT, A*, and R*. Our goal is to implement these algorithms to compare them with one another and determine their strengths and weaknesses. We also implement a minor extension to efficiently update the RRT in case of new obstacle information without re-planning from scratch.\nDemo running live on the server can be accessed here (might take a minute to spin up the server)\n","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"333661a41d6536ad3c40e6fa68d30c19","permalink":"https://parvparkhiya.github.io/project/planning/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/planning/","section":"project","summary":"Implemented various search based approaches for planning problem with non-holonomic constraints (RRT, A*, R*)","tags":["CMU","Robotics","Planning"],"title":"Trajectory Planning with non-holonomic constraints and obstacle avoidance","type":"project"},{"authors":null,"categories":null,"content":"Simultaneous Localization and Mapping (SLAM) is an essential part of any mobile robot. While the current stateof-the-art approach solves the problem in a static environment reasonably well, the performance in a dynamic environment is hit or miss. The traditional SLAM method assumes that the number of measurements from static objects would be large enough to dominate measurements from dynamic objects. We advocate for the explicit filtering of measurements from dynamic objects for better localization and mapping performance. We use the landscape theory of aggregation method to form an optimization problem. We observe the measurements for a timewindow and compute weights for the optimization. We perform gradient descent to minimize the energy to classify and filter out measurements from dynamic objects. Finally, using ROS’s GMapping Package we show improved SLAM output.\n","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"698ccabda8514f248725c288703bf0a6","permalink":"https://parvparkhiya.github.io/project/dslam/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/project/dslam/","section":"project","summary":"Implemented (C++) dynamic label classifier for SLAM pipeline with custom written optimizer on UGV robot","tags":["CMU","Robotics","SLAM"],"title":"Dynamic SLAM using landscape theory of aggregation [Implementation]","type":"project"},{"authors":null,"categories":null,"content":"Structural-fire has caused 2,640 civilian deaths and material loss of 9.7 Billion USD in the US alone in the year 2011 as per the National Fire Protection Association. Time is of the essence when it comes to tackling most of the fire incidents.\nThe PhoeniX team proposes a cutting-edge, fully autonomous, heterogeneous, multi-agent robotic systems to collaboratively locate and extinguish the fire without any human intervention in an unknown environment. Our system comprises a UAV (Unmanned Aerial Vehicle) and an AGV (Automated Ground Vehicle) equipped with a thermal camera that uses image segmentation methods for detecting and localizing the fire. Our system uses depth cameras to simultaneously create a real-time 3D map of the environment and localize itself in that map. The system uses state-of-the-art algorithms to explore the environment while avoiding collisions. The UAV has roughly 20 minutes of flight time, high payload capacity (1 Kg), and improved stability that can be attributed to its DJI Matrice M210 V2 platform. Both vehicles carry extinguishing material which they can strategically deploy on the target fire.\nThe UAV and the AGV share information of the fire location with each other to make smart decisions resulting in a timely \u0026amp; efficient response. The PhoeniX firefighting system attempts to push the technological boundaries to create a net positive impact on mankind.\n","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"0f6a5a16697e5f5e59eaff948ce8fe55","permalink":"https://parvparkhiya.github.io/project/phoenix/","publishdate":"2019-12-01T00:00:00Z","relpermalink":"/project/phoenix/","section":"project","summary":"Capstone project for Masters at CMU. Fully autonomous UAV (Unmanned Aerial Vehicle) and an AGV (Automated Ground Vehicle) system to detect, report, and extinguish fire","tags":["Robotics","CMU"],"title":"PhoeniX - UAV-AGV Firefighting System","type":"project"},{"authors":null,"categories":null,"content":"Modeled picking and placing trash bin skill using manipulator arm of Locobot robotic platform as Gaussian Process (GP) to enable imitation based skill learning from single demonstration\nThe objective of this project is to design a robot which can move a small trash can from its original place to a target place. Basically, what it should do are as follows: first, it should be able to navigate in the working environment. It should be able to detect the trash can, and move towards to it by using visual servoing. Then, it can use some grasping mechanism to carry the trash can with it and move to the target position. Finally, the robot puts down the trash can in the target area, and moves itself back to rest area. When conducting its mission, the robot should be able to hold the trash can steadily and not spill the trash out of the trash can. In addition, the robot is going to operate in the corridors in the teaching building, it should have a suitable physical size and make very little noise.\n","date":1556323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556323200,"objectID":"fe43fd76a30cac8c216750366ebc9700","permalink":"https://parvparkhiya.github.io/project/trash/","publishdate":"2019-04-27T00:00:00Z","relpermalink":"/project/trash/","section":"project","summary":"Modeled picking and placing trash bin skill using manipulator arm of Locobot robotic platform as Gaussian Process (GP) to enable imitation based skill learning from single demonstration","tags":["CMU","Robotics","Machine Learning"],"title":"Taking Out Trash","type":"project"},{"authors":["Nayan Joshi","Yogesh Sharma","Parv Parkhiya","Rishabh Khawad","K. Madhava Krishna","Brojeshwar Bhowmick"],"categories":null,"content":"","date":1543708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543708800,"objectID":"247044472ed14d84c0fff285f07104e8","permalink":"https://parvparkhiya.github.io/publication/line_object_slam/","publishdate":"2018-12-02T00:00:00Z","relpermalink":"/publication/line_object_slam/","section":"publication","summary":"We propose a novel Line based parameterization for category specific CAD models. The proposed parameterization associates 3D category-specific CAD model and object under consideration using a dictionary based RANSAC method that uses object Viewpoints as prior and edges detected in the respective intensity image of the scene.","tags":[],"title":"Integrating Objects into Monocular SLAM: Line Based Category Specific Models","type":"publication"},{"authors":null,"categories":null,"content":"Incorporated Dynamic Movement Primitives (DMP) approach to model stereo typical motion in data efficient manner and used that model to predict trajectory and goal location from a partially observed trajectory.\n","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"b944f85dbefa3500b40da8c77cbafc88","permalink":"https://parvparkhiya.github.io/project/dmp/","publishdate":"2018-12-01T00:00:00Z","relpermalink":"/project/dmp/","section":"project","summary":"Incorporated Dynamic Movement Primitives (DMP) approach to model stereo typical motion in data efficient manner and used that model to predict trajectory and goal location from a partially observed trajectory","tags":["CMU","Robotics","Machine Learning"],"title":"Modeling Motion of Stereotypical Dynamic Objects for Efficient Interaction","type":"project"},{"authors":null,"categories":null,"content":"We present a new paradigm for real-time object-oriented SLAM with a monocular camera. Contrary to previous approaches, that rely on object-level models, we construct category-level models from CAD collections which are now widely available. To alleviate the need for huge amounts of labeled data, we develop a rendering pipeline that enables synthesis of large datasets from a limited amount of manually labeled data. Using data thus synthesized, we learn category-models for object deformations in 3D, as well as discriminative object features in 2D. These category models are instance-independent and aid in the design of object landmark observations that can be incorporated into a generic monocular SLAM framework. Where typical object-SLAM approaches usually solve only for object and camera poses, we also estimate object shape on-the-fly, allowing for a wide range of objects from the category to be present in the scene. Moreover, since our 2D object features are learned discriminatively, the proposed object-SLAM system succeeds in several scenarios where sparse feature-based monocular SLAM fails due to insufficient features or parallax. Also, the proposed category-models help in object instance retrieval, useful for Augmented Reality (AR) applications. We evaluate the proposed framework on multiple challenging real-world scenes and show — to the best of our knowledge — first results of an instance-independent monocular object-SLAM system and the benefits it enjoys over feature-based SLAM methods.\n","date":1519948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519948800,"objectID":"b06119ebc7124200d2eef5604b4f2018","permalink":"https://parvparkhiya.github.io/project/oslam/","publishdate":"2018-03-02T00:00:00Z","relpermalink":"/project/oslam/","section":"project","summary":"Monocular Object-oriented Simultaneous Localization and Mapping (SLAM) using deep Convolutional Neural Network (CNN) and factor graph optimization","tags":["IIIT","Robotics","SLAM","Machine Learning","Computer Vision"],"title":"Constructing Category-Specific Models for Monocular Object-SLAM","type":"project"},{"authors":["Parv Parkhiya","Rishabh Khawad","J. Krishna Murthy","Brojeshwar Bhowmick","K. Madhava Krishna"],"categories":null,"content":" ","date":1519948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519948800,"objectID":"58d5bc684c6489df88dd78f2acde7031","permalink":"https://parvparkhiya.github.io/publication/object_slam/","publishdate":"2018-03-02T00:00:00Z","relpermalink":"/publication/object_slam/","section":"publication","summary":"We present a new paradigm for real-time object-oriented SLAM with a monocular camera. After 3D object shape and pose estimate from a single image using latest machine learning \u0026 keypoint reprojection error optimization, we show improvement in camera trajectory and object localization over current state of art monocular ORB-SLAM after merging odometry data from a feature based SLAM.","tags":[],"title":"Constructing Category-Specific Models for Monocular Object-SLAM","type":"publication"},{"authors":null,"categories":null,"content":"We apply the algorithm proposed by Chen etal to identify camera models. The algorithm assumes that CFA pattern used by the device is GBRG. Local co-occurrence features are computed using multiple interpolation algorithms (example nearest neighbour, bilinear). A multi-class linear SVM is trained with these features and employed to classify the given image to one of the camera classes. Some observations have been made with respect to validation accuracy of the model and the results obtained on Kaggle.\n","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"09f78e5ef914b9e96e9f72a9c1e978d3","permalink":"https://parvparkhiya.github.io/project/cmi/","publishdate":"2018-02-01T00:00:00Z","relpermalink":"/project/cmi/","section":"project","summary":"A multi-class linear SVM on extracted features","tags":["IIIT","Machine Learning"],"title":"Camera Model Identification","type":"project"},{"authors":null,"categories":null,"content":"We have developed a Matlab application to add 3D model of chair, lamp, cycle, vase etc in a captured real world image so that it could simulate how would room look like if the object was really present in that environment. For that, we place a simple marker where we have to put the 3D model and acquire the information of placement and orientation of the marker in 3d space, we place our 3D model with same orientation as that of marker. Followed by blending it with captured image.\n","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"4c8765b673e7842008f5d1bac2765111","permalink":"https://parvparkhiya.github.io/project/ar/","publishdate":"2016-12-01T00:00:00Z","relpermalink":"/project/ar/","section":"project","summary":"Add 3D model of chair, lamp, cycle, vase etc in a captured real world image","tags":["IIIT","Computer Vision"],"title":"Augmented Reality 3D Room Decore Preview","type":"project"},{"authors":null,"categories":null,"content":"Parameter sharing is the major reason of success of building large models for deep neural networks. The paper proposed by Shuangfei Zhai, Yu Cheng, Weining Lu and Zhongfei Zhang (NIPS 2016) introduces the idea of Doubly Convolutional Neural Networks, which significantly improves the performance of CNN with the same number of parameters. We have implemented DCNN as a part of Statistical Methods in AI Project.\n","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"03c45739e5033291d9d6a30a725af4c0","permalink":"https://parvparkhiya.github.io/project/dcnn/","publishdate":"2016-12-01T00:00:00Z","relpermalink":"/project/dcnn/","section":"project","summary":"Implemented extension of Convolutional Neural Network to reduce number of paramteres for similar performance","tags":["IIIT","Machine Learning"],"title":"Doubly Convolutional Neural Networks [Implementation]","type":"project"},{"authors":null,"categories":null,"content":"It’s a small narrative driven puzzle based top down 2D role-playing video game made in unity. It consists of original story with multiple choices at various stages leading to multiple endings. Along with giving historical perspective of medieval India, it challenges player with tough moral choices and situation based puzzles. Polished version of game is playable in windows using gyroscope sensor of android phone. Crude ported version can be played online using keyboard.\nPlay Online Here\n","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"7eb754a6be60cef2dfb016df27ee6593","permalink":"https://parvparkhiya.github.io/project/game/","publishdate":"2016-12-01T00:00:00Z","relpermalink":"/project/game/","section":"project","summary":"A narrative driven puzzle based role-playing with dialogues and choices created using Unity Engine","tags":["IIIT","Video Game","Other"],"title":"Video Game - Akbar-Birbal and the Mystery of Unaltered Dream","type":"project"}]